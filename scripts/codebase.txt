Here is my codebase:

<File: backend/adls.py>
#adls.py
"""
Connect to Azure Data Lake Storage Gen2 using DefaultAzureCredential
and perform basic operations like listing containers, uploading, downloading files, and creating directories.
"""

import os
from azure.storage.filedatalake import DataLakeServiceClient
from azure.identity import DefaultAzureCredential
from azure.core.exceptions import AzureError

# ============================================================================
# CONFIGURATION - UPDATE THESE VALUES
# ============================================================================
STORAGE_ACCOUNT_NAME = "djg0storage0shared"  # Replace with your storage account name
CONTAINER_NAME = "shared"              # Replace with your container/filesystem name
# ============================================================================

def connect_to_adls():
    """Connect to ADLS Gen2 using DefaultAzureCredential"""
    
    # Create the account URL using global config
    account_url = f"https://{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net/"
    
    try:
        # Create credential using DefaultAzureCredential
        # This will automatically use az login credentials
        credential = DefaultAzureCredential()
        
        # Create the DataLakeServiceClient
        service_client = DataLakeServiceClient(
            account_url=account_url,
            credential=credential
        )
        
        print(f"‚úÖ Successfully connected to {STORAGE_ACCOUNT_NAME}")
        return service_client
        
    except AzureError as e:
        print(f"‚ùå Azure error: {e}")
        return None
    except Exception as e:
        print(f"‚ùå Unexpected error: {e}")
        return None

def list_containers(service_client):
    """List all containers/file systems in the storage account"""
    try:
        print("\nüìÅ Available containers/file systems:")
        file_systems = service_client.list_file_systems()
        
        for fs in file_systems:
            print(f"  - {fs.name}")
            
    except AzureError as e:
        print(f"‚ùå Error listing containers: {e}")

def work_with_container(service_client, container_name):
    """Work with a specific container"""
    try:
        # Get file system client (container)
        file_system_client = service_client.get_file_system_client(container_name)
        
        # Check if container exists
        if file_system_client.exists():
            print(f"‚úÖ Container '{container_name}' exists")
        else:
            print(f"‚ö†Ô∏è Container '{container_name}' does not exist")
            # Optionally create it
            # file_system_client.create_file_system()
            # print(f"‚úÖ Created container '{container_name}'")
            return None
            
        return file_system_client
        
    except AzureError as e:
        print(f"‚ùå Error working with container: {e}")
        return None

def upload_file_example(file_system_client, local_file_path, remote_file_path):
    """Upload a file to ADLS Gen2"""
    try:
        # Get file client
        file_client = file_system_client.get_file_client(remote_file_path)
        
        # Read local file and upload
        with open(local_file_path, 'rb') as local_file:
            file_data = local_file.read()
            
            # Create file and upload data
            file_client.create_file()
            file_client.append_data(file_data, offset=0, length=len(file_data))
            file_client.flush_data(len(file_data))
            
        print(f"‚úÖ Uploaded '{local_file_path}' to '{remote_file_path}'")
        
    except FileNotFoundError:
        print(f"‚ùå Local file '{local_file_path}' not found")
    except AzureError as e:
        print(f"‚ùå Error uploading file: {e}")

def download_file_example(file_system_client, remote_file_path, local_file_path):
    """Download a file from ADLS Gen2"""
    try:
        # Get file client
        file_client = file_system_client.get_file_client(remote_file_path)
        
        # Download file
        with open(local_file_path, 'wb') as local_file:
            download = file_client.download_file()
            download.readinto(local_file)
            
        print(f"‚úÖ Downloaded '{remote_file_path}' to '{local_file_path}'")
        
    except AzureError as e:
        print(f"‚ùå Error downloading file: {e}")

def list_files_in_directory(file_system_client, directory_path=""):
    """List files and directories in a path"""
    try:
        print(f"\nüìÇ Contents of '{directory_path or 'root'}':")
        
        paths = file_system_client.get_paths(path=directory_path, recursive=False)
        
        for path in paths:
            path_type = "üìÅ DIR " if path.is_directory else "üìÑ FILE"
            print(f"  {path_type} {path.name}")
            
    except AzureError as e:
        print(f"‚ùå Error listing files: {e}")

def create_directory_example(file_system_client, directory_path):
    """Create a directory in ADLS Gen2"""
    try:
        directory_client = file_system_client.get_directory_client(directory_path)
        directory_client.create_directory()
        print(f"‚úÖ Created directory '{directory_path}'")
        
    except AzureError as e:
        print(f"‚ùå Error creating directory: {e}")

def main():
    """Main function to demonstrate ADLS Gen2 operations"""
    
    # Validate configuration
    if STORAGE_ACCOUNT_NAME == "your-storage-account-name" or CONTAINER_NAME == "your-container-name":
        print("‚ùå Please update STORAGE_ACCOUNT_NAME and CONTAINER_NAME at the top of this file!")
        return
    
    print("üöÄ Starting ADLS Gen2 Demo with DefaultAzureCredential")
    print("üìã Make sure you've run 'az login' first!")
    print(f"üìÅ Storage Account: {STORAGE_ACCOUNT_NAME}")
    print(f"üì¶ Container: {CONTAINER_NAME}")
    
    # Connect to ADLS
    service_client = connect_to_adls()
    if not service_client:
        print("‚ùå Failed to connect. Check your az login status and permissions.")
        return
    
    # List containers
    list_containers(service_client)
    
    # Work with specific container
    file_system_client = work_with_container(service_client, CONTAINER_NAME)
    if not file_system_client:
        print("‚ùå Cannot proceed without a valid container.")
        return
    
    # List files in root directory
    list_files_in_directory(file_system_client)
    
    # Example operations (uncomment to use):
    
    # Create a directory
    # create_directory_example(file_system_client, "test-directory")
    
    # Upload a file (make sure the local file exists)
    # upload_file_example(file_system_client, "local-file.txt", "remote-file.txt")
    
    # Download a file
    # download_file_example(file_system_client, "remote-file.txt", "downloaded-file.txt")
    
    # List files in a specific directory
    # list_files_in_directory(file_system_client, "test-directory")
    
    print("\n‚úÖ Demo completed successfully!")

if __name__ == "__main__":
    main()
--------------------------------------------------------------------------------
<File: backend/app.py>
# app.py ‚Äî FastAPI backend (PDF-only) with:
# - ADLS upload
# - Atomic PDF‚ÜíMarkdown twin generation
# - Single validation flow that always runs on Markdown twins
# - User-space bootstrap: creates required folders on first login (and idempotently elsewhere)

from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import os
import os.path as op
import mimetypes
import uuid
from typing import List, Optional
from tempfile import NamedTemporaryFile

from dotenv import load_dotenv

from azure.identity import DefaultAzureCredential
from azure.ai.projects import AIProjectClient
from azure.storage.filedatalake import DataLakeServiceClient
from azure.core.exceptions import AzureError

from azure.monitor.opentelemetry import configure_azure_monitor
from opentelemetry.instrumentation.openai_v2 import OpenAIInstrumentor

import tiktoken

from prompts import VALIDATION_SYSTEM_PROMPT, get_validation_user_prompt
from pdf_to_markdown_with_image_descriptions import pdf_to_markdown_with_image_text

# ------------------------------------------------------------------------------
# Environment & global setup
# ------------------------------------------------------------------------------

load_dotenv()

app = FastAPI(title="Document Validator API")

# CORS (open for dev; restrict origins in prod)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Azure AI Projects (for tracing + OpenAI client used in validation)
PROJECT_ENDPOINT = os.getenv("PROJECT_ENDPOINT")
MODEL_DEPLOYMENT_NAME = os.getenv("MODEL_DEPLOYMENT_NAME")
if not PROJECT_ENDPOINT or not MODEL_DEPLOYMENT_NAME:
    raise ValueError("PROJECT_ENDPOINT and MODEL_DEPLOYMENT_NAME must be set in environment")

project_client = AIProjectClient(credential=DefaultAzureCredential(), endpoint=PROJECT_ENDPOINT)
openai_client = project_client.get_openai_client(api_version="2024-02-01")

# Tracing (best-effort, non-fatal)
try:
    connection_string = project_client.telemetry.get_application_insights_connection_string()
    os.environ["AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED"] = "true"
    OpenAIInstrumentor().instrument()
    configure_azure_monitor(connection_string=connection_string)
    print("‚úÖ Tracing configured")
except Exception as e:
    print(f"‚ö†Ô∏è Tracing setup failed (continuing without tracing): {e}")

# ADLS config
STORAGE_ACCOUNT_NAME = os.getenv("STORAGE_ACCOUNT_NAME", "djg0storage0shared")
CONTAINER_NAME = os.getenv("CONTAINER_NAME", "shared")

# Tokenization constants
MAX_TOKENS = 50000
ENCODING_NAME = "cl100k_base"

# Simple user scoping (replace if/when you add auth)
HARDCODED_USER_ID = "dangiannone"

# ------------------------------------------------------------------------------
# Models
# ------------------------------------------------------------------------------

class ValidationResult(BaseModel):
    """Response for validation requests."""
    success: bool
    message: str
    raw_output: Optional[str] = None

class UploadResponse(BaseModel):
    """Response after uploading a PDF (raw + twin)."""
    success: bool
    message: str
    file_id: str
    file_path: str
    file_size: int
    original_filename: str
    markdown_file_path: Optional[str] = None

# ------------------------------------------------------------------------------
# ADLS helpers
# ------------------------------------------------------------------------------

def get_adls_client() -> DataLakeServiceClient:
    """Create an ADLS Gen2 service client using DefaultAzureCredential."""
    try:
        account_url = f"https://{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net/"
        credential = DefaultAzureCredential()
        return DataLakeServiceClient(account_url=account_url, credential=credential)
    except Exception as e:
        print(f"Failed to connect to ADLS: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to connect to storage: {str(e)}")

def ensure_user_folders_exist(service_client: DataLakeServiceClient, user_id: str):
    """
    Ensure container and user folders exist, including Markdown mirrors:
      <user_id>/
      <user_id>/input_docs
      <user_id>/reference_docs
      <user_id>/input_docs_md
      <user_id>/reference_docs_md
    Safe to call repeatedly (idempotent).
    """
    try:
        fs = service_client.get_file_system_client(CONTAINER_NAME)
        if not fs.exists():
            fs.create_file_system()
            print(f"‚úÖ Created container: {CONTAINER_NAME}")

        folders_to_create = [
            f"{user_id}",
            f"{user_id}/input_docs",
            f"{user_id}/reference_docs",
            f"{user_id}/input_docs_md",
            f"{user_id}/reference_docs_md",
        ]
        for folder_path in folders_to_create:
            try:
                dc = fs.get_directory_client(folder_path)
                if not dc.exists():
                    dc.create_directory()
                    print(f"‚úÖ Created directory: {folder_path}")
            except AzureError as e:
                if "PathAlreadyExists" not in str(e):
                    print(f"‚ö†Ô∏è Error creating directory {folder_path}: {e}")
        return fs
    except Exception as e:
        print(f"‚ùå Error ensuring folders exist: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to create user folders: {str(e)}")

def upload_file_to_adls(file_system_client, file_content: bytes, file_path: str) -> bool:
    """
    Upload a small/medium file to ADLS (single append+flush).
    Returns True if upload succeeds; raises HTTPException on failure.
    """
    try:
        fc = file_system_client.get_file_client(file_path)
        fc.create_file()
        fc.append_data(file_content, offset=0, length=len(file_content))
        fc.flush_data(len(file_content))
        print(f"‚úÖ Uploaded file to: {file_path}")
        return True
    except Exception as e:
        print(f"‚ùå Error uploading file to {file_path}: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to upload file: {str(e)}")

def download_file_from_adls(file_system_client, file_path: str) -> bytes:
    """Download the full contents of a file from ADLS as bytes."""
    try:
        fc = file_system_client.get_file_client(file_path)
        download = fc.download_file()
        return download.readall()
    except Exception as e:
        print(f"‚ùå Error downloading file from {file_path}: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to download file: {str(e)}")

def list_files_in_directory_detailed(file_system_client, directory_path: str) -> List[dict]:
    """
    List files in a directory and return minimal metadata for UI:
    file_path, original_filename, file_size, upload_date.
    """
    try:
        paths = file_system_client.get_paths(path=directory_path, recursive=False)
        files = []
        for p in paths:
            if not p.is_directory:
                fc = file_system_client.get_file_client(p.name)
                try:
                    props = fc.get_file_properties()
                    files.append({
                        "file_path": p.name,
                        "original_filename": os.path.basename(p.name),
                        "file_size": props.size,
                        "upload_date": props.last_modified.isoformat() if props.last_modified else None
                    })
                except Exception as e:
                    print(f"Error getting properties for {p.name}: {e}")
        return files
    except Exception as e:
        print(f"‚ùå Error listing files in {directory_path}: {e}")
        return []

def delete_file_from_adls(file_system_client, file_path: str) -> bool:
    """Delete a single file from ADLS. Returns True if deletion succeeded."""
    try:
        fc = file_system_client.get_file_client(file_path)
        fc.delete_file()
        print(f"‚úÖ Deleted file: {file_path}")
        return True
    except Exception as e:
        print(f"‚ùå Error deleting file {file_path}: {e}")
        return False

def adls_path_exists(file_system_client, file_path: str) -> bool:
    """Best-effort existence check by fetching file properties."""
    try:
        fc = file_system_client.get_file_client(file_path)
        _ = fc.get_file_properties()
        return True
    except Exception:
        return False

def safe_delete(file_system_client, path: str) -> bool:
    """Delete a path; swallow not-found errors (returns False on failure)."""
    try:
        fc = file_system_client.get_file_client(path)
        fc.delete_file()
        print(f"‚úÖ Deleted: {path}")
        return True
    except Exception as e:
        print(f"‚ÑπÔ∏è Skipped delete (likely missing): {path} ({e})")
        return False

# ------------------------------------------------------------------------------
# Markdown twin helpers (PDF-only)
# ------------------------------------------------------------------------------

def to_md_folder(raw_path: str) -> str:
    """
    Map a raw PDF path to its Markdown twin path:
      <user>/input_docs/foo.pdf -> <user>/input_docs_md/foo.md
      <user>/reference_docs/bar.pdf -> <user>/reference_docs_md/bar.md
    """
    parts = raw_path.split("/")
    if len(parts) < 3:
        raise ValueError(f"Unexpected path shape: {raw_path}")
    folder = parts[-2]  # e.g., input_docs
    if folder.endswith("_md"):
        base, _ = op.splitext(parts[-1])
        parts[-1] = base + ".md"
        return "/".join(parts)
    md_folder = folder + "_md"
    base, _ = op.splitext(parts[-1])
    parts[-2] = md_folder
    parts[-1] = base + ".md"
    return "/".join(parts)

def generate_markdown_from_pdf_bytes(file_bytes: bytes) -> str:
    """
    Convert in-memory PDF bytes to Markdown by writing a temporary file
    and running the PDF‚ÜíMarkdown pipeline (with image descriptions).
    Raises on failure.
    """
    with NamedTemporaryFile(suffix=".pdf", delete=True) as tmp:
        tmp.write(file_bytes)
        tmp.flush()
        return pdf_to_markdown_with_image_text(tmp.name)

# ------------------------------------------------------------------------------
# Upload endpoints ‚Äî transactional: raw PDF + Markdown twin OR fail
# ------------------------------------------------------------------------------

def _handle_upload_common_bytes(file_bytes: bytes, original_name: str, target_subdir: str) -> UploadResponse:
    """
    Core upload handler (pure sync): given the PDF bytes + original filename
    - Generate Markdown twin FIRST (in-memory); if it fails, abort
    - Upload BOTH raw PDF and MD twin to ADLS
    """
    # Generate Markdown FIRST to make the operation atomic
    try:
        md_text = generate_markdown_from_pdf_bytes(file_bytes)
    except Exception as e:
        print(f"‚ùå PDF‚ÜíMarkdown failed for {original_name}: {e}")
        raise HTTPException(status_code=502, detail="Failed to convert PDF to Markdown; upload aborted.")

    # ADLS setup & ensured folders
    service_client = get_adls_client()
    fs = ensure_user_folders_exist(service_client, HARDCODED_USER_ID)

    # Compute paths
    raw_path = f"{HARDCODED_USER_ID}/{target_subdir}/{original_name}"
    md_path = to_md_folder(raw_path)

    # Upload raw + twin
    upload_file_to_adls(fs, file_bytes, raw_path)
    upload_file_to_adls(fs, md_text.encode("utf-8"), md_path)

    return UploadResponse(
        success=True,
        message=f"Successfully uploaded {original_name} (+ Markdown twin)",
        file_id=str(uuid.uuid4()),
        file_path=raw_path,
        file_size=len(file_bytes),
        original_filename=original_name,
        markdown_file_path=md_path
    )

@app.post("/upload/input", response_model=UploadResponse)
async def upload_input_file(file: UploadFile = File(...)):
    """
    Upload an input PDF; create its Markdown twin; store both atomically.
    All async I/O (reading the upload) happens here; the rest is sync.
    """
    try:
        # Strict PDF-only guard
        content_type = (file.content_type or mimetypes.guess_type(file.filename)[0] or "").lower()
        _, ext = op.splitext(file.filename.lower())
        if content_type != "application/pdf" and ext != ".pdf":
            raise HTTPException(status_code=400, detail=f"Only PDF files are supported (got: {content_type or ext})")

        # Async read (FastAPI UploadFile)
        file_bytes = await file.read()

        # Ensure user dirs exist before any write (first login resilience)
        service_client = get_adls_client()
        ensure_user_folders_exist(service_client, HARDCODED_USER_ID)

        return _handle_upload_common_bytes(file_bytes, file.filename, "input_docs")
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Unexpected error uploading input file: {e}")
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")

@app.post("/upload/reference", response_model=UploadResponse)
async def upload_reference_file(file: UploadFile = File(...)):
    """
    Upload a reference PDF; create its Markdown twin; store both atomically.
    All async I/O (reading the upload) happens here; the rest is sync.
    """
    try:
        content_type = (file.content_type or mimetypes.guess_type(file.filename)[0] or "").lower()
        _, ext = op.splitext(file.filename.lower())
        if content_type != "application/pdf" and ext != ".pdf":
            raise HTTPException(status_code=400, detail=f"Only PDF files are supported (got: {content_type or ext})")

        file_bytes = await file.read()

        # Ensure user dirs exist before any write (first login resilience)
        service_client = get_adls_client()
        ensure_user_folders_exist(service_client, HARDCODED_USER_ID)

        return _handle_upload_common_bytes(file_bytes, file.filename, "reference_docs")
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Unexpected error uploading reference file: {e}")
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")

# ------------------------------------------------------------------------------
# List endpoints ‚Äî frontend shows PDFs only (raw folders)
# ------------------------------------------------------------------------------

@app.get("/files/input")
async def list_input_files():
    """
    List input PDFs for the current user (raw folder only, filtered to .pdf).
    Ensures folders exist first, so first-time users see an empty list rather than errors.
    """
    try:
        service_client = get_adls_client()
        fs = ensure_user_folders_exist(service_client, HARDCODED_USER_ID)
        input_dir = f"{HARDCODED_USER_ID}/input_docs"
        files = [f for f in list_files_in_directory_detailed(fs, input_dir) if f["original_filename"].lower().endswith(".pdf")]
        return {"files": files}
    except Exception as e:
        print(f"‚ùå Error listing input files: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to list files: {str(e)}")

@app.get("/files/reference")
async def list_reference_files():
    """
    List reference PDFs for the current user (raw folder only, filtered to .pdf).
    Ensures folders exist first, so first-time users see an empty list rather than errors.
    """
    try:
        service_client = get_adls_client()
        fs = ensure_user_folders_exist(service_client, HARDCODED_USER_ID)
        reference_dir = f"{HARDCODED_USER_ID}/reference_docs"
        files = [f for f in list_files_in_directory_detailed(fs, reference_dir) if f["original_filename"].lower().endswith(".pdf")]
        return {"files": files}
    except Exception as e:
        print(f"‚ùå Error listing reference files: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to list files: {str(e)}")

@app.get("/files/all")
async def list_all_files():
    """
    List all raw PDFs (input + reference) for the current user.
    Ensures folders exist first, so first-time users see empty lists rather than errors.
    """
    try:
        service_client = get_adls_client()
        fs = ensure_user_folders_exist(service_client, HARDCODED_USER_ID)
        input_dir = f"{HARDCODED_USER_ID}/input_docs"
        reference_dir = f"{HARDCODED_USER_ID}/reference_docs"
        input_files = [f for f in list_files_in_directory_detailed(fs, input_dir) if f["original_filename"].lower().endswith(".pdf")]
        reference_files = [f for f in list_files_in_directory_detailed(fs, reference_dir) if f["original_filename"].lower().endswith(".pdf")]
        return {"input_files": input_files, "reference_files": reference_files}
    except Exception as e:
        print(f"‚ùå Error listing all files: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to list files: {str(e)}")

# ------------------------------------------------------------------------------
# Delete endpoint ‚Äî removes raw PDF + Markdown twin together
# ------------------------------------------------------------------------------

@app.delete("/files/delete")
async def delete_file(file_path: str):
    """
    Delete a raw PDF and its Markdown twin.
    Accepts either the raw path (preferred) or the MD path; both companions are removed.
    Ensures folders exist so first-time calls don't fail due to missing container.
    """
    try:
        if not file_path.startswith(f"{HARDCODED_USER_ID}/"):
            raise HTTPException(status_code=403, detail="Access denied: Can only delete your own files")

        service_client = get_adls_client()
        fs = ensure_user_folders_exist(service_client, HARDCODED_USER_ID)

        deleted_any = False
        if "/input_docs_md/" in file_path or "/reference_docs_md/" in file_path:
            # If caller passed an MD path: delete MD and map back to raw (*.pdf)
            deleted_any = safe_delete(fs, file_path) or deleted_any
            parts = file_path.split("/")
            parts[-2] = parts[-2].replace("_md", "")
            stem, _ = op.splitext(parts[-1])
            raw_path = "/".join(parts[:-1] + [stem + ".pdf"])
            deleted_any = safe_delete(fs, raw_path) or deleted_any
        else:
            # Raw path: delete raw and derived MD twin
            deleted_any = safe_delete(fs, file_path) or deleted_any
            md_path = to_md_folder(file_path)
            deleted_any = safe_delete(fs, md_path) or deleted_any

        if deleted_any:
            return {"success": True, "message": f"Deleted {os.path.basename(file_path)} and any companions"}
        else:
            raise HTTPException(status_code=404, detail="Nothing deleted (file not found)")
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Error deleting file: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to delete file: {str(e)}")

# ------------------------------------------------------------------------------
# Validation ‚Äî single endpoint that always runs on Markdown twins
# ------------------------------------------------------------------------------

def count_tokens(text: str, encoding_name: str = ENCODING_NAME) -> int:
    """Count tokens for a given string using the configured encoding."""
    encoding = tiktoken.get_encoding(encoding_name)
    return len(encoding.encode(text))

def chunk_document(document: str, max_chunk_size: int, encoding_name: str = ENCODING_NAME) -> List[str]:
    """
    Split a document into chunks up to max_chunk_size tokens,
    preserving token boundaries for safer LLM input sizes.
    """
    encoding = tiktoken.get_encoding(encoding_name)
    tokens = encoding.encode(document)
    chunks = []
    for i in range(0, len(tokens), max_chunk_size):
        chunk_tokens = tokens[i:i+max_chunk_size]
        chunks.append(encoding.decode(chunk_tokens))
    return chunks

def validate_document_chunk(instructions: str, input_document: str, reference_chunk: str) -> str:
    """
    Call the LLM to validate the input document against one reference chunk.
    Returns raw Markdown content from the model.
    """
    user_prompt = get_validation_user_prompt(instructions, input_document, reference_chunk)
    messages = [
        {"role": "system", "content": VALIDATION_SYSTEM_PROMPT},
        {"role": "user", "content": user_prompt}
    ]
    try:
        response = openai_client.chat.completions.create(
            model=MODEL_DEPLOYMENT_NAME,
            messages=messages,
            temperature=0,
            max_tokens=1000
        )
        if response.choices:
            return response.choices[0].message.content
        else:
            return "No response from model"
    except Exception as e:
        print(f"Error during LLM call: {e}")
        return f"Error: {str(e)}"

def run_validation(input_markdown: str, reference_markdown: str, instructions: str) -> ValidationResult:
    """
    Core validation flow (strings in, strings out), chunking the reference
    to fit the context window and aggregating results.
    """
    try:
        system_tokens = count_tokens(VALIDATION_SYSTEM_PROMPT)
        instructions_tokens = count_tokens(f"Instructions: {instructions}")
        input_tokens = count_tokens(f"Input Document:\n{input_markdown}")

        user_prompt_template = get_validation_user_prompt("", "", "")
        template_overhead = count_tokens(user_prompt_template)

        total_overhead = system_tokens + instructions_tokens + input_tokens + template_overhead + 50  # buffer
        available_tokens = MAX_TOKENS - total_overhead

        if available_tokens <= 1000:
            return ValidationResult(
                success=False,
                message=f"Input document + overhead ({total_overhead} tokens) is too large. "
                        f"Available tokens for reference: {available_tokens}"
            )

        reference_chunks = chunk_document(reference_markdown, available_tokens)
        sections = []
        for i, chunk in enumerate(reference_chunks):
            result = validate_document_chunk(instructions, input_markdown, chunk)
            if result and result.strip():
                sections.append(f"## Analysis of Reference Section {i+1}\n\n{result}")

        if sections:
            return ValidationResult(
                success=True,
                message=f"Validation complete. Analyzed {len(reference_chunks)} reference document sections.",
                raw_output="\n\n---\n\n".join(sections)
            )
        else:
            return ValidationResult(
                success=True,
                message=f"Validation complete. Analyzed {len(reference_chunks)} reference document sections with no significant findings.",
                raw_output="No significant findings or issues identified in the validation."
            )
    except Exception as e:
        return ValidationResult(success=False, message=f"Error during validation: {str(e)}")

@app.post("/validate", response_model=ValidationResult)
async def validate_by_pdf_paths(
    input_pdf_path: str = Form(...),
    reference_pdf_path: str = Form(...),
    instructions: str = Form("")
):
    """
    Single validation endpoint:
      - Accepts ADLS paths of two PDFs (as shown to the user in the UI)
      - Maps them to their Markdown twins (created at upload time)
      - Ensures twins exist (no on-the-fly regeneration)
      - Downloads the twins and runs the core validation on Markdown only
    Ensures user folders exist first (first login resilience).
    """
    try:
        if not input_pdf_path.startswith(f"{HARDCODED_USER_ID}/") or not reference_pdf_path.startswith(f"{HARDCODED_USER_ID}/"):
            raise HTTPException(status_code=403, detail="Access denied: Can only validate your own files")

        service_client = get_adls_client()
        fs = ensure_user_folders_exist(service_client, HARDCODED_USER_ID)

        # Derive twin paths
        input_md_path = to_md_folder(input_pdf_path)
        ref_md_path = to_md_folder(reference_pdf_path)

        # Enforce presence of twins
        missing = []
        if not adls_path_exists(fs, input_md_path):
            missing.append(input_md_path)
        if not adls_path_exists(fs, ref_md_path):
            missing.append(ref_md_path)
        if missing:
            raise HTTPException(
                status_code=409,
                detail={"message": "Markdown twin(s) missing. Re-upload the PDF(s) to regenerate twins.", "missing": missing}
            )

        # Download twins
        input_md = download_file_from_adls(fs, input_md_path).decode("utf-8", errors="replace")
        ref_md = download_file_from_adls(fs, ref_md_path).decode("utf-8", errors="replace")

        # Run core validation on Markdown-only inputs
        return run_validation(input_md, ref_md, instructions)

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Error in /validate: {e}")
        return ValidationResult(success=False, message=f"Error during validation: {str(e)}")

# ------------------------------------------------------------------------------
# Login bootstrap ‚Äî call once when user signs in
# ------------------------------------------------------------------------------

@app.post("/init-user")
async def init_user():
    """
    Bootstrap the current user's ADLS namespace.
    Frontend should call this once right after login.
    Idempotent: safe to call multiple times.
    """
    try:
        service_client = get_adls_client()
        ensure_user_folders_exist(service_client, HARDCODED_USER_ID)
        return {"success": True, "message": "User folders ensured."}
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Error bootstrapping user folders: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to initialize user space: {str(e)}")

# ------------------------------------------------------------------------------
# Health
# ------------------------------------------------------------------------------

@app.get("/health")
async def health_check():
    """Simple health check (does not hit ADLS)."""
    return {"status": "healthy", "adls_connected": True}

# ------------------------------------------------------------------------------
# Entrypoint
# ------------------------------------------------------------------------------

if __name__ == "__main__":
    uvicorn.run("app:app", host="0.0.0.0", port=8000, reload=True)

--------------------------------------------------------------------------------
<File: backend/pdf_to_markdown_with_image_descriptions.py>
"""
pdf_to_markdown_with_image_descriptions.py
------------
1) Convert a PDF to Markdown with base64-embedded images (using pymupdf4llm).
2) For each embedded image, call LLM with the image *and* nearby text for additional context. LLM will return all the key info from the image.
3) Replace the image in the Markdown with the LLM's text
4) Return the final Markdown with images replaced by text descriptions.

Requirements:
  pip install pymupdf4llm azure-identity azure-ai-projects openai python-dotenv
"""

import os
import re
import sys
import argparse

import pymupdf4llm
from azure.identity import DefaultAzureCredential
from azure.ai.projects import AIProjectClient
from dotenv import load_dotenv

load_dotenv()

# ---- Config from environment ----
PROJECT_ENDPOINT = os.getenv("PROJECT_ENDPOINT")
MODEL_DEPLOYMENT_NAME = os.getenv("MODEL_DEPLOYMENT_NAME", "gpt-4.1")
AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-01")

# How much text (characters) to take before/after an image for "surrounding context"
CONTEXT_BEFORE_CHARS = int(os.getenv("VISION_CONTEXT_BEFORE_CHARS", "400"))
CONTEXT_AFTER_CHARS  = int(os.getenv("VISION_CONTEXT_AFTER_CHARS",  "400"))
MAX_CONTEXT_CHARS    = int(os.getenv("VISION_MAX_CONTEXT_CHARS",    "1000"))

# Matches: ![alt](data:image/<type>;base64,<B64...>)
IMAGE_DATAURI_PATTERN = re.compile(
    r"!\[[^\]]*\]\((data:image\/[a-zA-Z0-9.+-]+;base64,[A-Za-z0-9+/=\r\n]+)\)",
    re.DOTALL,
)

def get_openai_client():
    """Create the Azure AI Foundry OpenAI client using your pattern."""
    if not PROJECT_ENDPOINT:
        raise RuntimeError("PROJECT_ENDPOINT env var is required but missing.")
    print(f"üîó Connecting to Azure AI Foundry endpoint: {PROJECT_ENDPOINT}")
    project_client = AIProjectClient(
        credential=DefaultAzureCredential(),
        endpoint=PROJECT_ENDPOINT,
    )
    return project_client.get_openai_client(api_version=AZURE_OPENAI_API_VERSION)

# ---------- Helpers for context ----------

def strip_images_from_text(text: str) -> str:
    """Remove any base64 image markdown from the context to keep it small."""
    # Replace data-URI images with a short placeholder
    text = IMAGE_DATAURI_PATTERN.sub("[Image]", text)
    # (Optional) collapse any non-data image markdown too (kept simple)
    text = re.sub(r"!\[[^\]]*\]\([^)]+\)", "[ImageRef]", text)
    return text

def collapse_whitespace(text: str) -> str:
    """Make the context compact."""
    return re.sub(r"\s+", " ", text).strip()

def build_surrounding_context(markdown: str, start_idx: int, end_idx: int) -> str:
    """
    Grab a window of text around the image location, clean it, and cap its length.
    """
    before = markdown[max(0, start_idx - CONTEXT_BEFORE_CHARS): start_idx]
    after  = markdown[end_idx: min(len(markdown), end_idx + CONTEXT_AFTER_CHARS)]

    # Remove any inline images inside the window (so we don't leak big base64)
    before = strip_images_from_text(before)
    after  = strip_images_from_text(after)

    # Combine with a small marker so the model knows where the image was
    context = f"{before} [IMAGE LOCATION] {after}"
    context = collapse_whitespace(context)

    # Safety cap
    if len(context) > MAX_CONTEXT_CHARS:
        context = context[:MAX_CONTEXT_CHARS] + "‚Ä¶"
    return context

# ---------- PDF -> Markdown ----------

def convert_pdf_to_markdown(pdf_path: str) -> str:
    """Convert PDF to Markdown, embedding images as base64 data URLs (no disk writes)."""
    print(f"üìÑ Converting PDF to Markdown: {pdf_path}")
    result = pymupdf4llm.to_markdown(
        pdf_path,
        embed_images=True,
        write_images=False,
    )
    print("‚úÖ PDF converted successfully")
    return result

# ---------- Image description ----------

def describe_image(client, data_url: str, surrounding_context: str):
    """Send one data-URL image to the model and get a short description back."""
    # Extract image type for logging
    image_type_match = re.match(r"data:image\/([a-zA-Z0-9.+-]+);", data_url)
    image_type = image_type_match.group(1) if image_type_match else "unknown"

    print(f"  üì§ Sending {image_type} image to LLM...")
    print(f"  üß≠ Context length sent: {len(surrounding_context)} chars")

    messages = [
        {
            "role": "system",
            "content": (
                "You are a helpful assistant that looks at images and writes clear, detailed descriptions of the content. "
                "You will be provided with some surrounding context as well to better understand the image."
                "Just say what you see without saying 'the image contains' or similar phrases."
                "It is important that you capture all of the information that could be extracted from the image."
            ),
        },
        {
            "role": "user",
            "content": [
                {"type": "text", "text": f"Surrounding context: {surrounding_context}"},
                {"type": "image_url", "image_url": {"url": data_url, "detail": "high"}},
                
            ],
        },
    ]

    resp = client.chat.completions.create(
        model=MODEL_DEPLOYMENT_NAME,
        messages=messages,
        max_tokens=2000,
        temperature=0,
    )
    description = (resp.choices[0].message.content or "").strip()
    print(f"  üì• LLM response: \"{description}\"")
    return description

# ---------- Replace images with text ----------

def replace_images_with_text(markdown: str, client=None) -> str:
    """
    Find each base64 image, send it with nearby text, and replace it with a text line.

    Replacement format:
      > Image: <description>
    """
    parts = []
    last = 0

    # Collect matches up front so the indexes remain valid while we build `parts`
    all_matches = list(IMAGE_DATAURI_PATTERN.finditer(markdown))
    total_images = len(all_matches)

    if total_images == 0:
        print("‚ÑπÔ∏è  No images found in the markdown")
        return markdown

    print(f"üñºÔ∏è  Found {total_images} image(s) to process")
    print("-" * 60)

    for idx, match in enumerate(all_matches, 1):
        parts.append(markdown[last:match.start()])
        data_url = match.group(1)

        print(f"\nüìç Processing image {idx}/{total_images}")

        # Build surrounding context from the original markdown positions
        context = build_surrounding_context(markdown, match.start(), match.end())

        if client:
            try:
                desc = describe_image(client, data_url, context)
            except Exception as e:
                print(f"  ‚ö†Ô∏è  Error describing image: {e}")
                desc = ""
        else:
            print("  ‚ö†Ô∏è  No client available, skipping LLM description")
            desc = ""

        if desc:
            replacement = f"> Image: {desc}\n\n"
            print("  ‚úÖ Image replaced with description")
        else:
            replacement = "> Image: [description unavailable]\n\n"
            print("  ‚ö†Ô∏è  Using placeholder text (no description available)")

        parts.append(replacement)
        last = match.end()

    parts.append(markdown[last:])
    print("-" * 60)
    print(f"‚úÖ All {total_images} image(s) processed and replaced")

    return "".join(parts)

# ---------- Full pipeline ----------

def pdf_to_markdown_with_image_text(pdf_path: str) -> str:
    """PDF -> Markdown w/ base64 images -> ALWAYS replace images with text (+ context)."""
    print("=" * 60)
    print("üöÄ Starting PDF to Markdown conversion pipeline")
    print("=" * 60)

    md = convert_pdf_to_markdown(pdf_path)
    print(f"üìè Markdown size: {len(md):,} characters")

    try:
        client = get_openai_client()
        print(f"‚úÖ OpenAI client initialized (model: {MODEL_DEPLOYMENT_NAME})")
    except Exception as e:
        print(f"[warn] Could not initialize OpenAI client; images will be removed with placeholders. ({e})", file=sys.stderr)
        client = None

    result = replace_images_with_text(md, client)

    print("=" * 60)
    print("‚úÖ Pipeline complete")
    print("=" * 60)

    return result

# ---------- CLI ----------



def main():
    parser = argparse.ArgumentParser(description="PDF to Markdown, replacing images with LLM text (+ surrounding context).")
    parser.add_argument("input_pdf", help="Path to the input PDF")
    parser.add_argument(
        "-o", "--output",
        help="Path for the output .md file (default: <input_stem>.md in the same folder)",
    )
    args = parser.parse_args()

    input_pdf = args.input_pdf
    if not os.path.isfile(input_pdf):
        print(f"Error: file not found: {input_pdf}", file=sys.stderr)
        sys.exit(1)

    # Default output path: same folder as input, with .md
    if args.output:
        output_path = args.output
    else:
        folder = os.path.dirname(os.path.abspath(input_pdf))
        stem = os.path.splitext(os.path.basename(input_pdf))[0]
        output_path = os.path.join(folder, f"{stem}.md")

    print(f"üìÇ Input PDF: {input_pdf}")
    print(f"üìù Output will be saved to: {output_path}\n")

    result_md = pdf_to_markdown_with_image_text(input_pdf)

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(result_md)

    print(f"\n‚úÖ Wrote Markdown to: {output_path}")
    print(f"üìä Final file size: {len(result_md):,} characters")

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
<File: backend/prompts.py>
# prompts.py
"""
System and user prompts for document validation
"""

VALIDATION_SYSTEM_PROMPT = """You are an expert compliance analyst. Review the input document against the reference document section and provide a detailed analysis. 

Guidelines for your analysis:
- Be thorough but concise in your findings
- Use clear headers and bullet points for readability
- Highlight any compliance gaps, missing requirements, or inconsistencies
- Provide specific recommendations for improvement when applicable
- Reference specific sections or requirements from the reference document
- If no issues are found, clearly state that the document meets the requirements

Structure your response with clear markdown formatting for easy reading."""

def get_validation_user_prompt(instructions: str, input_document: str, reference_chunk: str) -> str:
    """Generate the user prompt for validation"""
    return f"""
Instructions: {instructions if instructions.strip() else "Perform a general compliance validation"}

Input Document:
{input_document}

Reference Document Section:
{reference_chunk}

Please analyze the input document against this reference document section and provide your findings.
"""

# Additional prompts can be added here as the system grows
SUMMARIZATION_SYSTEM_PROMPT = """You are an expert at summarizing technical documents. Provide clear, concise summaries that capture the key points."""

COMPARISON_SYSTEM_PROMPT = """You are an expert at comparing documents. Identify similarities, differences, and gaps between documents."""
--------------------------------------------------------------------------------
<File: frontend/src/components/DocumentValidator.tsx>
"use client";

import React, { useState, useEffect } from 'react';
import { Upload, File, Play, CheckCircle, AlertCircle, Loader } from 'lucide-react';
import ReactMarkdown from 'react-markdown';

// Simplified type definitions
interface ValidationResult {
  success: boolean;
  message: string;
  raw_output?: string; // Add this for the raw LLM output
}

interface UploadResponse {
  success: boolean;
  message: string;
  file_id: string;
  file_path: string;
  file_size: number;
  original_filename: string;
}

interface FileInfo {
  file_path: string;
  original_filename: string;
  file_size: number;
  upload_date: string;
}

interface FileWithStatus {
  file?: File;
  status: 'uploading' | 'completed' | 'error' | 'removing';
  id: string;
  file_path?: string;
  file_id?: string;
  error_message?: string;
  original_filename: string;
  file_size: number;
  upload_date?: string;
  is_existing?: boolean;
}

const API_BASE_URL = 'http://localhost:8000';

const DocumentValidator: React.FC = () => {
  const [inputFile, setInputFile] = useState<FileWithStatus | null>(null);
  const [referenceFiles, setReferenceFiles] = useState<FileWithStatus[]>([]);
  const [instructions, setInstructions] = useState<string>('');
  const [isRunning, setIsRunning] = useState<boolean>(false);
  const [results, setResults] = useState<ValidationResult | null>(null);
  const [error, setError] = useState<string | null>(null);

  const generateFileId = () => Math.random().toString(36).substr(2, 9);

  // Load existing files on component mount
  useEffect(() => {
    loadExistingFiles();
  }, []);

  const loadExistingFiles = async () => {
    try {
      const response = await fetch(`${API_BASE_URL}/files/all`);
      if (response.ok) {
        const data = await response.json();
        
        const convertToFileWithStatus = (fileInfo: FileInfo): FileWithStatus => ({
          status: 'completed' as const,
          id: generateFileId(),
          file_path: fileInfo.file_path,
          original_filename: fileInfo.original_filename,
          file_size: fileInfo.file_size,
          upload_date: fileInfo.upload_date,
          is_existing: true
        });

        if (data.input_files && data.input_files.length > 0) {
          const inputFile = convertToFileWithStatus(data.input_files[0]);
          setInputFile(inputFile);
        }

        if (data.reference_files && data.reference_files.length > 0) {
          const refFiles = data.reference_files.map((fileInfo: FileInfo) => 
            convertToFileWithStatus(fileInfo)
          );
          setReferenceFiles(refFiles);
        }
      }
    } catch (error) {
      console.error('Error loading existing files:', error);
    }
  };

  const handleFileUpload = (file: File, type: string): void => {
    const fileId = generateFileId();
    const fileWithStatus: FileWithStatus = {
      file,
      status: 'uploading',
      id: fileId,
      original_filename: file.name,
      file_size: file.size
    };

    if (type === 'input') {
      setInputFile(fileWithStatus);
    } else if (type === 'reference') {
      setReferenceFiles(prev => [...prev, fileWithStatus]);
    }

    uploadFileToBackend(file, type, fileId);
  };

  const uploadFileToBackend = async (file: File, type: string, fileId: string): Promise<void> => {
    try {
      const formData = new FormData();
      formData.append('file', file);

      const endpoint = type === 'input' ? '/upload/input' : '/upload/reference';
      
      const response = await fetch(`${API_BASE_URL}${endpoint}`, {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({ detail: 'Upload failed' }));
        throw new Error(errorData.detail || `HTTP error! status: ${response.status}`);
      }

      const uploadResponse: UploadResponse = await response.json();

      if (uploadResponse.success) {
        if (type === 'input') {
          setInputFile(prev => prev && prev.id === fileId ? {
            ...prev,
            status: 'completed',
            file_path: uploadResponse.file_path,
            file_id: uploadResponse.file_id,
            original_filename: uploadResponse.original_filename,
            file_size: uploadResponse.file_size
          } : prev);
        } else if (type === 'reference') {
          setReferenceFiles(prev => 
            prev.map(f => f.id === fileId ? {
              ...f,
              status: 'completed',
              file_path: uploadResponse.file_path,
              file_id: uploadResponse.file_id,
              original_filename: uploadResponse.original_filename,
              file_size: uploadResponse.file_size
            } : f)
          );
        }
      } else {
        throw new Error(uploadResponse.message || 'Upload failed');
      }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Upload failed';
      console.error(`‚ùå Upload error for ${file.name}:`, error);
      
      if (type === 'input') {
        setInputFile(prev => prev && prev.id === fileId ? {
          ...prev,
          status: 'error',
          error_message: errorMessage
        } : prev);
      } else if (type === 'reference') {
        setReferenceFiles(prev => 
          prev.map(f => f.id === fileId ? {
            ...f,
            status: 'error',
            error_message: errorMessage
          } : f)
        );
      }
    }
  };

  const removeFile = async (type: string, id: string): Promise<void> => {
    try {
      let fileToRemove: FileWithStatus | null | undefined;
      
      if (type === 'input') {
        fileToRemove = inputFile;
      } else if (type === 'reference') {
        fileToRemove = referenceFiles.find(f => f.id === id);
      }

      if (type === 'input' && inputFile) {
        setInputFile(prev => prev ? { ...prev, status: 'removing' } : prev);
      } else if (type === 'reference') {
        setReferenceFiles(prev => 
          prev.map(f => f.id === id ? { ...f, status: 'removing' } : f)
        );
      }

      if (fileToRemove && fileToRemove.file_path && (fileToRemove.status === 'completed' || fileToRemove.status === 'removing')) {
        const deleteResponse = await fetch(`${API_BASE_URL}/files/delete?file_path=${encodeURIComponent(fileToRemove.file_path)}`, {
          method: 'DELETE',
        });

        if (!deleteResponse.ok) {
          const errorData = await deleteResponse.json().catch(() => ({ detail: 'Delete failed' }));
          throw new Error(errorData.detail || 'Failed to delete file');
        }
      }

      if (type === 'input') {
        setInputFile(null);
      } else if (type === 'reference') {
        setReferenceFiles(prev => prev.filter(f => f.id !== id));
      }
    } catch (error) {
      console.error('Error removing file:', error);
      
      if (type === 'input' && inputFile) {
        setInputFile(prev => prev ? { ...prev, status: 'completed', error_message: 'Failed to remove file' } : prev);
      } else if (type === 'reference') {
        setReferenceFiles(prev => 
          prev.map(f => f.id === id ? { ...f, status: 'error', error_message: 'Failed to remove file' } : f)
        );
      }
      
      setError(error instanceof Error ? error.message : 'Failed to remove file');
    }
  };

  const runValidation = async (): Promise<void> => {
    if (!inputFile || inputFile.status !== 'completed' || !inputFile.file_path) {
      setError('Please upload an input document');
      return;
    }

    const completedReferenceFiles = referenceFiles.filter(f => f.status === 'completed' && f.file_path);
    if (completedReferenceFiles.length === 0) {
      setError('Please upload at least one reference document');
      return;
    }

    setIsRunning(true);
    setError(null);
    setResults(null);

    try {
      const formData = new FormData();
      formData.append('input_file_path', inputFile.file_path);
      formData.append('reference_file_path', completedReferenceFiles[0].file_path!);
      formData.append('instructions', instructions);

      const response = await fetch(`${API_BASE_URL}/validate-uploaded`, {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({ detail: 'Validation failed' }));
        throw new Error(errorData.detail || `HTTP error! status: ${response.status}`);
      }

      const data: ValidationResult = await response.json();
      setResults(data);
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'An unknown error occurred';
      setError(errorMessage);
      console.error('Validation error:', err);
    } finally {
      setIsRunning(false);
    }
  };

  const getStatusIcon = (status: 'uploading' | 'completed' | 'error' | 'removing') => {
    switch (status) {
      case 'uploading':
        return <Loader className="h-4 w-4 text-blue-500 animate-spin" />;
      case 'removing':
        return <Loader className="h-4 w-4 text-red-500 animate-spin" />;
      case 'completed':
        return <CheckCircle className="h-4 w-4 text-green-500" />;
      case 'error':
        return <AlertCircle className="h-4 w-4 text-red-500" />;
    }
  };

  const getStatusText = (fileWithStatus: FileWithStatus) => {
    switch (fileWithStatus.status) {
      case 'uploading':
        return 'Uploading...';
      case 'removing':
        return 'Removing...';
      case 'completed':
        return 'Ready';
      case 'error':
        return fileWithStatus.error_message || 'Upload failed';
    }
  };

  const FileUploadSection: React.FC<{
    title: string;
    files: FileWithStatus[];
    onFileChange: (file: File, type: string) => void;
    type: string;
    multiple?: boolean;
  }> = ({ title, files, onFileChange, type, multiple = false }) => (
    <div className="border-2 border-dashed border-gray-300 rounded-lg p-6 hover:border-gray-400 transition-colors">
      <div className="text-center">
        <Upload className="mx-auto h-8 w-8 text-gray-400" />
        <div className="mt-2">
          <label htmlFor={`file-${type}`} className="cursor-pointer">
            <span className="block text-sm font-medium text-gray-700">{title}</span>
            <span className="block text-xs text-gray-500 mt-1">
              Click to upload{multiple ? ' (multiple files supported)' : ''}
            </span>
          </label>
          <input
            id={`file-${type}`}
            type="file"
            className="hidden"
            accept=".txt,.pdf,.doc,.docx"
            multiple={multiple}
            onChange={(e: React.ChangeEvent<HTMLInputElement>) => {
              const selectedFiles = Array.from(e.target.files || []);
              selectedFiles.forEach(file => onFileChange(file, type));
              e.target.value = '';
            }}
          />
        </div>
      </div>
      
      {files.length > 0 && (
        <div className="mt-4 space-y-2">
          {files.map((fileWithStatus) => (
            <div key={fileWithStatus.id} className="flex items-center justify-between p-3 bg-gray-50 rounded">
              <div className="flex items-center flex-1">
                <File className="h-4 w-4 text-gray-500 mr-2" />
                <div className="flex-1 min-w-0">
                  <div className="flex items-center gap-2">
                    <span className="text-sm text-gray-900 truncate">{fileWithStatus.original_filename}</span>
                    {getStatusIcon(fileWithStatus.status)}
                  </div>
                  <span className="text-xs text-gray-500">{getStatusText(fileWithStatus)}</span>
                </div>
              </div>
              <button
                onClick={() => removeFile(type, fileWithStatus.id)}
                className="text-red-600 hover:text-red-800 text-sm ml-2 disabled:opacity-50"
                disabled={fileWithStatus.status === 'uploading' || fileWithStatus.status === 'removing'}
              >
                Remove
              </button>
            </div>
          ))}
        </div>
      )}
    </div>
  );

  const hasCompletedInputFile = inputFile?.status === 'completed' && inputFile.file_path;
  const completedReferenceFiles = referenceFiles.filter(f => f.status === 'completed' && f.file_path);
  const hasCompletedReferenceFiles = completedReferenceFiles.length > 0;
  const canRunValidation = hasCompletedInputFile && hasCompletedReferenceFiles;

  return (
    <div className="min-h-screen bg-gray-50 p-6">
      <div className="max-w-4xl mx-auto">
        {/* Header */}
        <div className="mb-8 text-center">
          <h1 className="text-3xl font-bold text-gray-900 mb-2">Document Validator</h1>
          <p className="text-gray-600">Upload documents and validate them against reference materials</p>
        </div>

        {/* File Upload Sections */}
        <div className="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6">
          <FileUploadSection
            title="Input Document"
            files={inputFile ? [inputFile] : []}
            onFileChange={handleFileUpload}
            type="input"
            multiple={false}
          />
          <FileUploadSection
            title="Reference Documents"
            files={referenceFiles}
            onFileChange={handleFileUpload}
            type="reference"
            multiple={true}
          />
        </div>

        {/* Instructions Section */}
        <div className="mb-6">
          <div className="bg-white rounded-lg p-4 border border-gray-200">
            <label htmlFor="instructions" className="block text-sm font-medium text-gray-700 mb-2">
              Validation Instructions (Optional)
            </label>
            <textarea
              id="instructions"
              rows={3}
              className="w-full px-3 py-2 border border-gray-300 rounded focus:ring-blue-500 focus:border-blue-500"
              placeholder="Enter specific instructions for validation..."
              value={instructions}
              onChange={(e: React.ChangeEvent<HTMLTextAreaElement>) => setInstructions(e.target.value)}
            />
          </div>
        </div>

        {/* Run Button */}
        <div className="mb-6 text-center">
          <button
            onClick={runValidation}
            disabled={isRunning || !canRunValidation}
            className="inline-flex items-center px-6 py-3 border border-transparent text-base font-medium rounded-md shadow-sm text-white bg-blue-600 hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500 disabled:opacity-50 disabled:cursor-not-allowed"
          >
            {isRunning ? (
              <>
                <Loader className="animate-spin -ml-1 mr-3 h-5 w-5 text-white" />
                Running Validation...
              </>
            ) : (
              <>
                <Play className="-ml-1 mr-3 h-5 w-5" />
                Run Validation
              </>
            )}
          </button>
          {!canRunValidation && (
            <p className="mt-2 text-sm text-gray-500">
              Upload both input and reference documents to continue
            </p>
          )}
        </div>

        {/* Error Display */}
        {error && (
          <div className="mb-6 rounded-md bg-red-50 p-4 border border-red-200">
            <div className="flex">
              <AlertCircle className="h-5 w-5 text-red-500" />
              <div className="ml-3">
                <h3 className="text-sm font-medium text-red-800">Error</h3>
                <div className="mt-2 text-sm text-red-700">{error}</div>
              </div>
            </div>
          </div>
        )}

        {/* Results Display - Simplified */}
        {results && (
          <div className="bg-white rounded-lg p-6 border border-gray-200">
            <h2 className="text-xl font-bold text-gray-900 mb-4">Validation Results</h2>
            
            {results.success ? (
              <div>
                <div className="flex items-center text-green-600 bg-green-50 p-3 rounded-md border border-green-200 mb-4">
                  <CheckCircle className="h-5 w-5 mr-2" />
                  <span className="font-medium">{results.message}</span>
                </div>
                
                {/* Simple markdown output */}
                {results.raw_output && (
                  <div className="prose prose-slate max-w-none prose-headings:text-gray-900 prose-p:text-gray-800 prose-li:text-gray-800 prose-strong:text-gray-900">
                    <ReactMarkdown
                      components={{
                        h1: (props: any) => <h1 className="text-xl font-bold text-gray-900 mb-3 mt-6 first:mt-0" {...props} />,
                        h2: (props: any) => <h2 className="text-lg font-semibold text-gray-900 mb-2 mt-5 first:mt-0" {...props} />,
                        h3: (props: any) => <h3 className="text-lg font-bold text-gray-900 mb-2 mt-4 first:mt-0" {...props} />,
                        p: (props: any) => <p className="mb-3 text-gray-800 leading-relaxed" {...props} />,
                        ul: (props: any) => <ul className="list-disc list-inside mb-3 space-y-1" {...props} />,
                        ol: (props: any) => <ol className="list-decimal list-inside mb-3 space-y-1" {...props} />,
                        li: (props: any) => <li className="text-gray-800 leading-relaxed" {...props} />,
                        strong: (props: any) => <strong className="font-semibold text-gray-900" {...props} />,
                        em: (props: any) => <em className="italic text-gray-700" {...props} />,
                        code: (props: any) => <code className="bg-gray-100 px-2 py-1 rounded text-gray-900 font-mono text-sm" {...props} />,
                        blockquote: (props: any) => <blockquote className="border-l-4 border-gray-300 pl-4 italic text-gray-700 my-4 bg-gray-50 py-2" {...props} />,
                        hr: (props: any) => <hr className="my-6 border-gray-300" {...props} />
                      }}
                    >
                      {results.raw_output}
                    </ReactMarkdown>
                  </div>
                )}
              </div>
            ) : (
              <div className="rounded-md bg-red-50 p-4 border border-red-200">
                <div className="flex">
                  <AlertCircle className="h-5 w-5 text-red-500" />
                  <div className="ml-3">
                    <h3 className="text-sm font-medium text-red-800">Validation Failed</h3>
                    <div className="mt-2 text-sm text-red-700">{results.message}</div>
                  </div>
                </div>
              </div>
            )}
          </div>
        )}
      </div>
    </div>
  );
};

export default DocumentValidator;
--------------------------------------------------------------------------------

<end codebase> 

